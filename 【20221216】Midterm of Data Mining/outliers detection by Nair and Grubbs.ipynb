{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 离群值检测实验报告：Nair检测法和Grubbs检测法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 盛焕新      15220202202189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 离群值检测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df, cv_table, sigma, alpha_jianchu, alpha_tichu, side='both'):\n",
    "    \"\"\"\n",
    "    函数说明：\n",
    "    df: 用于检测离群值的数据集\n",
    "    cv_table: 用于表示Nair或Grubbs的临界值表\n",
    "    sigma: 表示正态分布的标准差\n",
    "    alpha_jianchu: 表示检出水平\n",
    "    alpha_tichu: 表示剔除水平\n",
    "    side: 有三种情况，'upper', 'lower', 'both', 分别代表上侧、下侧和双侧, 默认为双侧\n",
    "    \"\"\"\n",
    "    #首先将数据进行排序，并计算个数及其均值\n",
    "    data = sorted(df.values.flatten())\n",
    "    n = len(data)\n",
    "    u = np.mean(data)\n",
    "    \n",
    "    #找出参数情况下的检出水平和剔除水平\n",
    "    P_jianchu = cv_table.loc[cv_table['n']==n, (1 - alpha_jianchu)].item()\n",
    "    P_tichu = cv_table.loc[cv_table['n']==n, (1 - alpha_tichu)].item()\n",
    "    \n",
    "    #设置两个变量用来统计离群值和歧离值的个数\n",
    "    i = 0 #表示离群值的个数，第i个\n",
    "    j = 0 #表示歧离值的个数，第j个\n",
    "\n",
    "            \n",
    "     #上侧情形：\n",
    "    if side == 'upper':\n",
    "        while True:\n",
    "            P_last = (data[-1] - u) / sigma\n",
    "            \n",
    "            if P_last > P_jianchu: #确认最上侧的值是否高于检出水平\n",
    "                if P_last > P_tichu:#既然能被检出，确定是否需要剔除\n",
    "                    i = i+1\n",
    "                    print(f'检测出第{i}个统计离群值{data[-1]}')#找到需要剔除的值，即为统计离群值\n",
    "                else:\n",
    "                    j = j+1\n",
    "                    print(f'检测出第{j}个歧离值：{data[-1]}')#并没有到需要剔除的水平，即为歧离值\n",
    "                data = data[: -1]\n",
    "                continue\n",
    "\n",
    "            else:   \n",
    "                print(f'*总结：共检测出{i}个统计离群值和{j}个歧离值！')\n",
    "                return pd.DataFrame(data, columns=df.columns)\n",
    "\n",
    "    \n",
    "    #下侧情形：\n",
    "    if side == 'lower':\n",
    "        while True:\n",
    "            P_first = (u - data[0]) / sigma\n",
    "\n",
    "            if P_first > P_jianchu:#确认最下侧的值是否高于检出水平\n",
    "                if P_first > P_tichu: #既然能被检出，确定是否需要剔除\n",
    "                    i = i+1\n",
    "                    print(f'检测出第{i}个统计离群值：{data[0]}')#找到需要剔除的值，即为统计离群值\n",
    "                else:\n",
    "                    j = j+1\n",
    "                    print(f'检测出第{j}个歧离值：{data[0]}')#并没有到需要剔除的水平，即为歧离值\n",
    "                data = data[1: ]\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print(f'*总结：共检测出{i}个统计离群值和{j}个歧离值！')\n",
    "                return pd.DataFrame(data, columns=df.columns)\n",
    "        \n",
    "            \n",
    "    #双侧情形：\n",
    "    if side == 'both':\n",
    "        while True:\n",
    "            P_first = (u - data[0]) / sigma\n",
    "            P_last = (data[-1] - u) / sigma\n",
    "\n",
    "            #双侧情况比较复杂，需要比较P_first和P_last的关系\n",
    "            if P_first == P_last and P_first > P_critical_jianchu:\n",
    "                    if P_first > P_tichu:\n",
    "                        i = i+1\n",
    "                        print(f'检测出第{i}个统计离群值（位于下侧）：{data[0]}')#找到需要剔除的值，即为统计离群值\n",
    "                    else:\n",
    "                        j = j+1\n",
    "                        print(f'检测出第{j}个歧离值（位于下侧）：{data[0]}')#并没有到需要剔除的水平，即为歧离值\n",
    "                        \n",
    "                    if P_last > P_tichu:\n",
    "                        i = i+1\n",
    "                        print(f'检测出第{i}个统计离群值（位于上侧）：{data[-1]}')#找到需要剔除的值，即为统计离群值\n",
    "                    else:\n",
    "                        j = j+1\n",
    "                        print(f'检测出第{j}歧离值（位于上侧）：{data[-1]}')#并没有到需要剔除的水平，即为歧离值\n",
    "                    data = data[1: -1]\n",
    "                    \n",
    "            elif P_first > P_last and P_first > P_jianchu:\n",
    "                if P_first > P_tichu:\n",
    "                    i = i+1\n",
    "                    print(f'检测出第{i}个统计离群值（位于下侧）：{data[0]}')#找到需要剔除的值，即为统计离群值\n",
    "                else:\n",
    "                    j = j+1\n",
    "                    print(f'检测出第{j}个歧离值（位于下侧）：{data[0]}')#并没有到需要剔除的水平，即为歧离值\n",
    "                data = data[1: ]        \n",
    "                    \n",
    "            elif P_last > P_first and P_last > P_jianchu:\n",
    "                if P_last > P_tichu:\n",
    "                    i = i+1\n",
    "                    print(f'检测出第{i}个统计离群值（位于上侧）：{data[-1]}')#找到需要剔除的值，即为统计离群值\n",
    "                else:\n",
    "                    j = j+1\n",
    "                    print(f'检测出第{j}个歧离值（位于上侧）：{data[-1]}')#并没有到需要剔除的水平，即为歧离值\n",
    "                data = data[: -1]\n",
    "\n",
    "            else:   \n",
    "                print(f'*总结：共检测出{i}个统计离群值和{j}个歧离值！')\n",
    "                return pd.DataFrame(data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实验执行及结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Nair检测法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nair检测实验结果:\n",
      "\n",
      "①双侧情形:\n",
      "检测出第1个统计离群值（位于下侧）：3.13\n",
      "*总结：共检测出1个统计离群值和0个歧离值！\n",
      "\n",
      "②上侧情形:\n",
      "*总结：共检测出0个统计离群值和0个歧离值！\n",
      "\n",
      "③下侧情形:\n",
      "检测出第1个统计离群值：3.13\n",
      "*总结：共检测出1个统计离群值和0个歧离值！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('./Data source/Data source.csv')\n",
    "cv_Nair = pd.read_excel('./Data source/Critical value table of Nair.xlsx')\n",
    "cv_Nair.columns = ['n'] + cv_Nair.columns[1: ].map(lambda x: float(x[6: ])).tolist()\n",
    "\n",
    "print('Nair检测实验结果:')\n",
    "\n",
    "print('\\n①双侧情形:')\n",
    "Nair_both = find_outliers(df=data, cv_table=cv_Nair, sigma=0.65, alpha_jianchu=0.05, alpha_tichu=0.01)\n",
    "\n",
    "print('\\n②上侧情形:')\n",
    "Nair_upper = find_outliers(df=data, cv_table=cv_Nair, sigma=0.65, alpha_jianchu=0.05, alpha_tichu=0.01, side='upper')\n",
    "\n",
    "print('\\n③下侧情形:')\n",
    "Nair_lower = find_outliers(df=data, cv_table=cv_Nair, sigma=0.65, alpha_jianchu=0.05, alpha_tichu=0.01, side='lower')\n",
    "\n",
    "    \"\"\"\n",
    "    调用说明：\n",
    "    df: 用于检测离群值的数据集\n",
    "    cv_table: 用于表示Nair或Grubbs的临界值表\n",
    "    sigma: 表示正态分布的标准差\n",
    "    alpha_jianchu: 表示检出水平\n",
    "    alpha_tichu: 表示剔除水平\n",
    "    side: 有三种情况，'upper', 'lower', 'both', 分别代表上侧、下侧和双侧, 默认为双侧\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Grubbs检测法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grubbs检测实验结果:\n",
      "\n",
      "①双侧情形：\n",
      "检测出第1个统计离群值（位于下侧）：3.13\n",
      "检测出第1个歧离值（位于下侧）：3.49\n",
      "*总结：共检测出1个统计离群值和1个歧离值！\n",
      "\n",
      "②上侧情形:\n",
      "*总结：共检测出0个统计离群值和0个歧离值！\n",
      "\n",
      "③下侧情形:\n",
      "检测出第1个统计离群值：3.13\n",
      "检测出第1个歧离值：3.49\n",
      "*总结：共检测出1个统计离群值和1个歧离值！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('./Data source/Data source.csv')\n",
    "cv_Grubbs = pd.read_excel('./Data source/Critical value table of Grubbs.xlsx')\n",
    "cv_Grubbs.columns = ['n'] + cv_Grubbs.columns[1: ].map(lambda x: float(x[6: ])).tolist()\n",
    "\n",
    "print('Grubbs检测实验结果:')\n",
    "\n",
    "print('\\n①双侧情形：')\n",
    "Grubbs_both = find_outliers(df=data, cv_table=cv_Grubbs, sigma=0.65, alpha_jianchu=0.05, alpha_tichu=0.01)\n",
    "\n",
    "print('\\n②上侧情形:')\n",
    "Grubbs_upper = find_outliers(df=data, cv_table=cv_Grubbs, sigma=0.65, alpha_jianchu=0.05, alpha_tichu=0.01, side='upper')\n",
    "\n",
    "print('\\n③下侧情形:')\n",
    "Grubbs_lower = find_outliers(df=data, cv_table=cv_Grubbs, sigma=0.65, alpha_jianchu=0.05, alpha_tichu=0.01, side='lower')\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    调用说明：\n",
    "    df: 用于检测离群值的数据集\n",
    "    cv_table: 用于表示Nair或Grubbs的临界值表\n",
    "    sigma: 表示正态分布的标准差\n",
    "    alpha_jianchu: 表示检出水平\n",
    "    alpha_tichu: 表示剔除水平\n",
    "    side: 有三种情况，'upper', 'lower', 'both', 分别代表上侧、下侧和双侧, 默认为双侧\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 实验总结："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上可得，Nair检测法和Grubbs检测法都是检测离群值和歧离值的方法。根据国标数据，可以得出结论："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   3.1 使用Nair检测法得出结果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "①双侧情形:\n",
    "\n",
    "    检测出第1个统计离群值（位于下侧）：3.13\n",
    "\n",
    "*总结：共检测出1个统计离群值和0个歧离值！\n",
    "\n",
    "\n",
    "②上侧情形:\n",
    "\n",
    "*总结：共检测出0个统计离群值和0个歧离值！\n",
    "\n",
    "\n",
    "③下侧情形:\n",
    "\n",
    "    检测出第1个统计离群值：3.13\n",
    "\n",
    "*总结：共检测出1个统计离群值和0个歧离值！\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   3.2 使用Grubbs检测法得出结果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "①双侧情形：\n",
    "\n",
    "    检测出第1个统计离群值（位于下侧）：3.13\n",
    "\n",
    "    检测出第1个歧离值（位于下侧）：3.49\n",
    "\n",
    "*总结：共检测出1个统计离群值和1个歧离值！\n",
    "\n",
    "②上侧情形:\n",
    "\n",
    "*总结：共检测出0个统计离群值和0个歧离值！\n",
    "\n",
    "③下侧情形:\n",
    "\n",
    "    检测出第1个统计离群值：3.13\n",
    "\n",
    "    检测出第1个歧离值：3.49\n",
    "\n",
    "*总结：共检测出1个统计离群值和1个歧离值！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "42cc27f5a6c36577eca79f4721c34abb67162958417b94f4c20013378ef11f88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
